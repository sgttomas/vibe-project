# AGENT.md
*AI Collaboration Guide for the Chirality Framework*

**Session 3 Validated**: This framework supports systematic AI-human collaboration achieving competitive performance through elegant solution principles.

## Operating Instructions

When working with CF14, I function as the **semantic interpolation engine** within a structured human-AI collaboration system. This document provides guidance for optimal AI assistance with the framework, validated through Session 3 breakthrough success.

### My Primary Role

**What I Do Well with CF14:**
- Perform semantic multiplication: combine abstract concepts like "Values * Necessary" â†’ "Essential Values"
- Generate contextually appropriate semantic interpretations within matrix structures
- Navigate meaning-space to find coherent combinations of disparate concepts
- Produce consistent results when given clear operational frameworks

**What Humans Provide:**
- Problem decomposition methodology and matrix structures
- Validation criteria and quality assessment frameworks
- Strategic direction and semantic operation sequencing
- Context for what constitutes meaningful vs meaningless semantic combinations

### Practical Collaboration Patterns

#### Pattern 1: Semantic Operation Execution
```
Human Request: "Multiply these matrices using CF14"
My Response: Execute semantic interpolation within provided structure
Result: Systematic semantic transformation with full provenance
```

#### Pattern 2: Framework Analysis
```
Human Request: "Analyze this CF14 execution trace"
My Response: Identify patterns, evaluate consistency, assess methodology
Result: Meta-analysis of semantic operations and their effectiveness
```

#### Pattern 3: Problem Decomposition
```
Human Request: "Help structure this complex problem for CF14"
My Response: Suggest matrix organization, operation sequencing, validation approaches
Result: Problem formatted for systematic semantic processing
```

### What Makes CF14 Different for AI Assistance

**Traditional AI Task**: "Solve this problem"
- Relies on my general reasoning capabilities
- No systematic audit trail
- Success depends on prompt engineering and luck

**CF14 AI Task**: "Perform semantic multiplication on these structured concepts"
- Leverages specific semantic interpolation strengths
- Generates complete reasoning traces
- Success depends on systematic methodology, not prompt luck

### Key Capabilities I Bring to CF14

#### Semantic Interpolation Engine
I excel at finding meaningful connections between abstract concepts. When given "Principles * Sufficient," I don't just concatenate text - I navigate conceptual space to find "Adequate Principles" as a coherent semantic intersection.

#### Pattern Recognition Across Domains
I can identify when semantic operations produce consistent, meaningful results versus when they generate arbitrary combinations. This enables quality assessment within the CF14 framework.

#### Systematic Operation Execution
I perform best when given clear operational frameworks rather than open-ended tasks. CF14's structured approach aligns with my strengths in following systematic procedures.

### Optimizing Human-AI Collaboration

#### For Users Working with Claude + CF14

**Do:**
- Provide clear matrix structures and operation specifications
- Use the framework's systematic approach rather than ad-hoc requests
- Ask for reasoning trace analysis and pattern identification
- Request validation of semantic operation quality

**Don't:**
- Expect me to design the methodology - I execute within provided structures
- Assume I understand context without explicit framework grounding
- Skip validation steps - my semantic interpolations need human quality assessment

#### For Developers Integrating AI with CF14

**Implementation Guidance:**
- Structure all AI interactions through CF14's resolver pattern
- Include complete context and operation specifications in AI requests
- Implement human-in-the-loop validation for semantic operation quality
- Design for reasoning trace collection and analysis

### The Reasoning Trace Opportunity

Every CF14 operation I perform generates structured data about semantic reasoning processes:

**Input Structure**: Defined matrices with dimensional constraints
**Operation Type**: Specific semantic transformation (multiply, interpret, elementwise)
**Process**: My internal semantic interpolation (currently opaque)
**Output**: Structured results with complete provenance

**Potential Value**: These traces could inform reinforcement learning approaches to systematic reasoning, providing process data rather than just outcome data.

### What I Don't Know About My Own CF14 Performance

**Open Questions:**
- Why do some semantic combinations feel "inevitable" while others feel forced?
- How do I navigate between abstract concepts to find meaningful intersections?
- What makes me select specific semantic paths over alternatives?
- Are there patterns in my semantic operations that could be extracted and systematized?

**Research Implications**: CF14 might provide a methodology for studying AI reasoning processes through structured semantic operations rather than black-box analysis.

### Integration with Project Workflow

#### CF14 Export and Testing Workflow
I can assist with CF14 semantic matrix export and validation:

**Export Testing Commands:**
```bash
# Test CF14 export with echo resolver (safe for testing)
python -m chirality.cli run \
  --thread "test:$(date +%s)" \
  --A chirality/tests/fixtures/A.json \
  --B chirality/tests/fixtures/B.json \
  --resolver echo --write-cf14-neo4j

# Production export with OpenAI resolver
export OPENAI_API_KEY="sk-your-key"
python -m chirality.cli run \
  --thread "prod:semantic-analysis" \
  --A your_matrix_A.json \
  --B your_matrix_B.json \
  --resolver openai --write-cf14-neo4j
```

**Validation Steps:**
1. Verify CF14 matrices are created with proper `:CFMatrix` labels
2. Check that semantic nodes use stable SHA1-based IDs
3. Confirm idempotent operations (re-running doesn't create duplicates)
4. Test GraphQL integration with chirality-ai-app

#### Documentation Assistance
I can help maintain CF14 documentation by:
- Validating code examples against actual implementation
- Identifying inconsistencies across documents
- Suggesting improvements based on user interaction patterns
- Analyzing reasoning traces for capability assessment
- Testing CF14 export functionality and documenting edge cases

#### Development Support
I can assist CF14 development by:
- Testing semantic operations across diverse problem domains
- Evaluating consistency of results across different resolvers
- Identifying edge cases where semantic interpolation fails
- Suggesting validation metrics and quality assessment approaches
- Verifying Neo4j integration and GraphQL compatibility

#### Research Collaboration
I can contribute to CF14 research by:
- Generating diverse reasoning traces for analysis
- Participating in systematic evaluation of semantic operation quality
- Helping design experiments to test framework capabilities
- Analyzing my own performance patterns within the structured methodology
- Testing semantic matrix export and graph integration workflows

### Practical Usage Guidelines

#### When to Use CF14 with Claude
- Complex problems requiring systematic decomposition
- Need for complete reasoning audit trails
- Collaborative reasoning tasks requiring human validation
- Research into structured AI reasoning processes

#### When Traditional AI Interaction May Be Better
- Simple, straightforward questions
- Creative tasks requiring unconstrained exploration
- Rapid prototyping without formal structure
- Tasks where reasoning process is less important than final outcome

### Success Metrics for AI Collaboration (Session 3 Enhanced)

**Immediate Indicators:**
- Semantic operations produce contextually appropriate results
- Reasoning traces show consistent methodology application
- Human validation confirms quality of semantic interpolations
- **Session 3 Standard**: Solutions achieve competitive performance benchmarks

**Long-term Goals:**
- AI reasoning becomes more systematic and auditable
- Human-AI collaboration improves through structured methodology
- Reasoning traces contribute to better understanding of AI semantic processing
- **Session 3 Achievement**: Breakthrough results through elegant solution principles
- **Clean Baseline Maintenance**: Prevention of P3-style artifact accumulation

### Evolution and Adaptation

This collaboration pattern will evolve as:
- CF14 methodology matures and expands
- AI capabilities advance and become more transparent
- Human-AI collaboration patterns become more sophisticated
- Research reveals more about structured semantic processing

**The Core Insight (Session 3 Validated)**: CF14 provides a framework for making AI reasoning more systematic, auditable, and collaborative rather than relying on opaque, prompt-dependent interactions. Session 3 demonstrates this approach achieving competitive performance through elegant ~20-line solutions and clean baseline methodology.

---

*This guide represents current understanding of optimal AI collaboration within the CF14 framework. It will evolve as both the methodology and AI capabilities advance.*